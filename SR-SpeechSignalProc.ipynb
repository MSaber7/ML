{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SR-SpeechSignalProc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMI5Zzj2EFD/wNNvvcUwHAV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSaber7/Machine-Learning/blob/master/SR-SpeechSignalProc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paxWpmr2cOqg",
        "colab_type": "text"
      },
      "source": [
        "# SR | Lab Two: Speech Signal Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl8nMlx3cOhI",
        "colab_type": "text"
      },
      "source": [
        "In this lab, you will write the core functions necessary to perform feature extraction on audio waveforms. Your program will convert an audio file to a sequence of log mel frequency filterbank (\"FBANK\") coefficients.\n",
        "The basic steps in features extraction are:\n",
        "Dithering & pre-emphasis of the waveform\n",
        "Dividing the signal into overlapping segments or frames\n",
        "For each frame of audio:\n",
        "Windowing the frame\n",
        "Computing the magnitude spectrum of the frame\n",
        "Applying the mel filterbank to the spectrum to create mel filterbank coefficient\n",
        "Applying a logarithm operation to the mel filterbank coefficient\n",
        "File speech_sigproc.py contains methods for performing these steps. Functions for dithering (1a), framing (2) and windowing (3a) are already implemented as well as method process_utterance which applies all needed methods one after another. Your task is to:\n",
        "Implement pre-emphasis of the signal as method pre_emphasize \n",
        "Implement computation of magnitude spectrum as method frames_to_magspec. (Note: the variable fft_size is useful there)\n",
        "Implement the application of mel filterbank and logarithm operation as method magspec_to_fbank (Note: the coefficients of the melt filterbank are computed and saved as mel_filterbank 2-D array. \n",
        "\n",
        "The lab also contain following files:\n",
        "1272-128104-0000.flac -- audio file from LibriSpeech library, which is a clean sample of english speech\n",
        "1272-128104-0000.feat -- file which contains data about expected result of feature extraction for mentioned audio file \n",
        "htk_featio.py -- additional file for extracting data from .feat file\n",
        "plotter.py -- script which consistently performs following steps:\n",
        "Reads the wav file and extracts features from it with method process_utterance from speech_sigproc.py \n",
        "Plot the original waveform, the mel filterbank, the expected and gained results of feature extraction\n",
        "Computes per-element absolute error of the feature extraction (Note: if you did everything correctly, the expected error is less than 1e-08).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GeOz2HKfkpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "370f1ad1-dc63-4a3e-fedf-0763ea414495"
      },
      "source": [
        "pip install soundfile"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.13.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.19)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8wV1pZ4dMPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubx4Y2sHevRA",
        "colab_type": "text"
      },
      "source": [
        "### Define FrontEnd Model : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVkMBNR8cMxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FrontEnd:\n",
        "\n",
        "    def __init__(self, samp_rate=16000, frame_duration=0.025, frame_shift=0.010, preemphasis=0.97,\n",
        "                 num_mel=40, lo_freq=0, hi_freq=None, mean_norm_feat=False, mean_norm_wav=True, compute_stats=False):\n",
        "        self.samp_rate = samp_rate\n",
        "        self.win_size = int(np.floor(frame_duration * samp_rate))\n",
        "        self.win_shift = int(np.floor(frame_shift * samp_rate))\n",
        "        self.lo_freq = lo_freq\n",
        "        if (hi_freq == None):\n",
        "            self.hi_freq = samp_rate//2\n",
        "        else:\n",
        "            self.hi_freq = hi_freq\n",
        "\n",
        "        self.preemphasis = preemphasis\n",
        "        self.num_mel = num_mel\n",
        "        self.fft_size = 2\n",
        "        while (self.fft_size<self.win_size):\n",
        "            self.fft_size *= 2\n",
        "\n",
        "        self.hamwin = np.hamming(self.win_size)\n",
        "\n",
        "        self.make_mel_filterbank()\n",
        "        self.zero_mean_wav = mean_norm_wav\n",
        "        self.global_mean = np.zeros([num_mel])\n",
        "        self.global_var = np.zeros([num_mel])\n",
        "        self.global_frames = 0\n",
        "        self.compute_global_stats = compute_stats\n",
        "\n",
        "    # linear-scale frequency (Hz) to mel-scale frequency\n",
        "    def lin2mel(self,freq):\n",
        "        return 2595*np.log10(1+freq/700)\n",
        "\n",
        "    # mel-scale frequency to linear-scale frequency\n",
        "    def mel2lin(self,mel):\n",
        "        return (10**(mel/2595)-1)*700\n",
        "\n",
        "    def make_mel_filterbank(self):\n",
        "\n",
        "        lo_mel = self.lin2mel(self.lo_freq)\n",
        "        hi_mel = self.lin2mel(self.hi_freq)\n",
        "\n",
        "        # uniform spacing on mel scale\n",
        "        mel_freqs = np.linspace(lo_mel, hi_mel,self.num_mel+2)\n",
        "\n",
        "        # convert mel freqs to hertz and then to fft bins\n",
        "        bin_width = self.samp_rate/self.fft_size # typically 31.25 Hz, bin[0]=0 Hz, bin[1]=31.25 Hz,..., bin[256]=8000 Hz\n",
        "        mel_bins = np.floor(self.mel2lin(mel_freqs)/bin_width)\n",
        "\n",
        "        num_bins = self.fft_size//2 + 1\n",
        "        self.mel_filterbank = np.zeros([self.num_mel,num_bins])\n",
        "        for i in range(0,self.num_mel):\n",
        "            left_bin = int(mel_bins[i])\n",
        "            center_bin = int(mel_bins[i+1])\n",
        "            right_bin = int(mel_bins[i+2])\n",
        "            up_slope = 1/(center_bin-left_bin)\n",
        "            for j in range(left_bin,center_bin):\n",
        "                self.mel_filterbank[i,j] = (j - left_bin)*up_slope\n",
        "            down_slope = -1/(right_bin-center_bin)\n",
        "            for j in range(center_bin,right_bin):\n",
        "                self.mel_filterbank[i,j] = (j-right_bin)*down_slope\n",
        "\n",
        "    def plot_mel_matrix(self):\n",
        "        for i in range(0, self.num_mel):\n",
        "            plt.plot(self.mel_filterbank[i,:])\n",
        "        plt.show()\n",
        "\n",
        "    def dither(self, wav):\n",
        "        n = 2*np.random.rand(wav.shape[0])-1\n",
        "        n *= 1/(2**15)\n",
        "        return wav + n\n",
        "\n",
        "    # replace this with proper pre-emphasis filtering, using the self.preemphasis coefficient\n",
        "    def pre_emphasize(self, wav):\n",
        "        # apply pre-emphasis filtering on waveform\n",
        "        preemph_wav = []\n",
        "        return preemph_wav\n",
        "\n",
        "    def wav_to_frames(self, wav):\n",
        "        # wav1 = np.array(wav)\n",
        "        # only process whole frames\n",
        "        num_frames = int(np.floor((wav.shape[0] - self.win_size) / self.win_shift) + 1)\n",
        "        frames = np.zeros([self.win_size, num_frames])\n",
        "        for t in range(0, num_frames):\n",
        "            frame = wav[t * self.win_shift:t * self.win_shift + self.win_size]\n",
        "            if (self.zero_mean_wav):\n",
        "                frame = frame - np.mean(frame)\n",
        "            frames[:, t] = self.hamwin * frame\n",
        "        return frames\n",
        "\n",
        "    # for each frame (column of 2D array 'frames'), compute the magnitude spectrum using the fft\n",
        "    def frames_to_magspec(self, frames):\n",
        "        # compute the fft\n",
        "        # compute magnitude\n",
        "        magspec = []\n",
        "        return magspec\n",
        "\n",
        "    # for each frame(column of 2D array 'magspec'), compute the log mel spectrum, by applying the mel filterbank to the magnitude spectrum\n",
        "    def magspec_to_fbank(self, magspec):\n",
        "        # apply the mel filterbank\n",
        "        fbank = []\n",
        "        return fbank\n",
        "\n",
        "    def process_utterance(self, utterance):\n",
        "   #     plt.plot(utterance)\n",
        "   #     plt.show()\n",
        "        wav     = self.dither(utterance)\n",
        "        wav     = self.pre_emphasize(wav)\n",
        "        frames  = self.wav_to_frames(wav)\n",
        "        magspec = self.frames_to_magspec(frames)\n",
        "        fbank   = self.magspec_to_fbank(magspec)\n",
        "        return fbank"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvwCngo2eenY",
        "colab_type": "text"
      },
      "source": [
        "### Read File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQQbWxPXdy-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "b300b174-622e-4f8c-ba24-2c1a5e6898c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEbcOTN3eBLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c89d8626-d1d0-45b6-a261-f1ddfca7bb82"
      },
      "source": [
        "%cd/content/drive/My Drive/Colab Notebooks/SR/Lab2"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/SR/Lab2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stJaOgeycMtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wav_file=\"1272-128104-0000.flac\"\n",
        "feat_file=\"1272-128104-0000.feat\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZk8Iqrhec_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, s = sf.read(wav_file)\n",
        "fe = FrontEnd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpi7X10KcMsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aa = fe.pre_emphasize(x)\n",
        "bb = fe.wav_to_frames(wav)\n",
        "cc = fe.frames_to_magspec(bb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoPuJDG6kBkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#wav = np.array(aa)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj3JYVATfcc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVuqhjKwkzQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}