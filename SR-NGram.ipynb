{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SR-NGram.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+UsCXz2vJ/WoXg2a7Hfdk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSaber7/Machine-Learning/blob/master/SR-NGram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J51c5VHCxLc3",
        "colab_type": "text"
      },
      "source": [
        "# SR | Lab Three : N-Gram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk0UA7-FxUfg",
        "colab_type": "text"
      },
      "source": [
        "Implement an N-Gram language model that can separate true sentences from the artificially obtained sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80EL8_phxjn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "ALPHA = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMwvkJLexCrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LanguageModel(object):\n",
        "    \"\"\"\n",
        "        n-gramm model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ngram_size=2):\n",
        "\n",
        "        if ngram_size < 2:\n",
        "            raise Exception\n",
        "\n",
        "        self.ngram_size = ngram_size\n",
        "\n",
        "        #keys of dictionary are all words that was read by model, values are their ids (tokens)\n",
        "        self.dictionary = {}\n",
        "        self.number_of_words = 0\n",
        "\n",
        "        #counters has n-grams and {n-1)-grams as keys and number of their occurances in train set as values\n",
        "        self.counter = {}\n",
        "        self.context_counter = {}\n",
        "\n",
        "        self.smoothing = 'laplace'\n",
        "\n",
        "    def fit(self, sentences):\n",
        "        \"\"\"\n",
        "            Model training on sentence-splitted text\n",
        "            :param sentences: the list of sentences\n",
        "        \"\"\"\n",
        "        for sentence in sentences:\n",
        "            self.fit_sentence(self.tokenize_sentence(sentence))\n",
        "\n",
        "    def tokenize_sentence(self, sentence):\n",
        "        \"\"\"\n",
        "            Getting the list of tokens by the sentence\n",
        "            :return: tokenized sentence\n",
        "        \"\"\"\n",
        "\n",
        "        #TODO: Your code for task #4\n",
        "\n",
        "        sentence = sentence.split(\" \")\n",
        "\n",
        "        sentence.insert(0, '^')\n",
        "        sentence.insert(-1, '$')\n",
        "\n",
        "        result = []\n",
        "\n",
        "        for word in sentence:\n",
        "            token = self.dictionary.get(word)\n",
        "\n",
        "            #if word is not in dictionary, then we should add it and set a token to it\n",
        "            if token is None:\n",
        "                token = self.number_of_words\n",
        "                self.dictionary.setdefault(word, token)\n",
        "                self.number_of_words = self.number_of_words + 1\n",
        "\n",
        "            result.append(token)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def fit_sentence(self, sentence):\n",
        "        \"\"\"\n",
        "            Fitting a sentence to a model\n",
        "        \"\"\"\n",
        "\n",
        "        l = len(sentence)\n",
        "\n",
        "        #we should count ever n-gram in the sentence\n",
        "        for i in range(l - self.ngram_size + 1):\n",
        "            ngram = tuple(sentence[i: i + self.ngram_size])\n",
        "            val = self.counter.get(ngram, 0) + 1\n",
        "            self.counter.update([(ngram, val)])\n",
        "\n",
        "        #... and do the same with {n-1}-grams, which are contexts for n-grams\n",
        "        #TODO: Your code for task #1. Count the occurences in self.context_counter\n",
        "\n",
        "        for j in range(l - self.ngram_size + 2):\n",
        "            n_1gram = tuple(sentence[j: j + self.ngram_size - 1])\n",
        "            val = self.context_counter.get(n_1gram,0) + 1\n",
        "            self.context_counter.update([(n_1gram,val)])\n",
        "\n",
        "    def ngram_prob(self, ngram):\n",
        "        \"\"\"\n",
        "            Counting the probability of n-gram by knowing the context\n",
        "        \"\"\"\n",
        "        if(self.smoothing == 'laplace'):\n",
        "\n",
        "            #context for a n-gram is this n-gram without last word (token)\n",
        "            context = ngram[:-1]\n",
        "\n",
        "            #amount of unique {n-1}-grams\n",
        "            V = len(self.context_counter.keys())\n",
        "\n",
        "            #amount of occurances of given n-gram and its context in train set\n",
        "            ngram_count = self.counter.get(ngram, 0)\n",
        "            context_count = self.context_counter.get(context, 0)\n",
        "\n",
        "            #TODO: Your code for task #2\n",
        "            ngram_prob = (ngram_count + ALPHA)/(context_count + ALPHA * V)\n",
        "\n",
        "            return ngram_prob\n",
        "\n",
        "    def sentence_logprob(self, sentence):\n",
        "        \"\"\"\n",
        "            Counting the log of probability of the given sentence as sum of log probabilities of its n-grams\n",
        "        \"\"\"\n",
        "\n",
        "        sentence = self.tokenize_sentence(sentence)\n",
        "\n",
        "        l = len(sentence)\n",
        "        logprob = 0\n",
        "\n",
        "        #TODO: Your code for task #3\n",
        "        for i in range(l - self.ngram_size + 1):\n",
        "            gram = tuple(sentence[i: i + self.ngram_size])\n",
        "            tem_logprob = np.log(self.ngram_prob(gram))\n",
        "            logprob += tem_logprob\n",
        "\n",
        "        return logprob\n",
        "\n",
        "    def log_prob(self, sentences):\n",
        "        return [self.sentence_logprob(sentence) for sentence in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nkya6_Nx6__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "5beed387-d6b9-4543-fdbf-7b197eb4f916"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEZrRepFxx2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60e3ea64-53d1-45b2-fefb-1f2146a3566b"
      },
      "source": [
        "%cd/content/drive/My Drive/Colab Notebooks/SR/Lab3"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/SR/Lab3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5l1ar1GyreX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "cadb517f-b396-4c90-ea68-b54eaf28f3d4"
      },
      "source": [
        "df_train = pd.read_csv(\"train.tsv\", sep='\\t')\n",
        "df_test = pd.read_csv(\"task.tsv\", sep='\\t')\n",
        "\n",
        "print(df_train.head(2))\n",
        "print(\"Read \", df_train.shape, df_test.shape)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id                                               text\n",
            "0   0  старый запустить палаццо с высокий лепной плаф...\n",
            "1   1       на угол он встретить спешить ночное извозчик\n",
            "Read  (15119, 2) (7048, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRwAv5HXy0KO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9afc76f-6782-4348-c604-e68cd804df26"
      },
      "source": [
        "basic_lm = LanguageModel()\n",
        "\n",
        "sentences_train = df_train[\"text\"].tolist()\n",
        "basic_lm.fit(sentences=sentences_train)\n",
        "\n",
        "print(\"Trained\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trained\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh3V6Phgy46O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test1, test2 = df_test[\"text1\"], df_test[\"text2\"]\n",
        "\n",
        "logprob1, logprob2 = np.array(basic_lm.log_prob(test1)), np.array(basic_lm.log_prob(test2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paN7d1FXxCq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = pd.DataFrame()\n",
        "res[\"id\"] = df_test[\"id\"]\n",
        "res[\"which\"] = 0\n",
        "res.loc[logprob2 >= logprob1, [\"which\"]] = 1\n",
        "\n",
        "res.to_csv(\"submission.csv\", sep=\",\", index=None, columns=[\"id\", \"which\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xu_T0xmxCph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fraaIJ_axCiV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "e08843f0-9bd0-4287-8d78-d5fa864be17f"
      },
      "source": [
        "sub = pd.read_csv(\"submission.csv\")\n",
        "print (sub)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        id  which\n",
            "0        0      1\n",
            "1        1      1\n",
            "2        2      1\n",
            "3        3      0\n",
            "4        4      0\n",
            "...    ...    ...\n",
            "7043  7043      0\n",
            "7044  7044      0\n",
            "7045  7045      1\n",
            "7046  7046      0\n",
            "7047  7047      0\n",
            "\n",
            "[7048 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stDQBrVVxCfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}